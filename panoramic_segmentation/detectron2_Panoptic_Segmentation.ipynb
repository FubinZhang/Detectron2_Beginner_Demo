{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyNtvnDlzXtwUTaqolVMXsLT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 环境配置"],"metadata":{"id":"o8gTwSmrsYTW"}},{"cell_type":"code","source":["# !nvidia-smi\n","import torch\n","print(torch.__version__)\n","torch.cuda.set_device(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4v-8BjZsaxv","executionInfo":{"status":"ok","timestamp":1694077792485,"user_tz":-480,"elapsed":5105,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"ced65c0d-85b4-41a5-b13b-b36ffe6daddf"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}]},{"cell_type":"code","source":["# 连接网盘\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1db17PE3scst","executionInfo":{"status":"ok","timestamp":1694077815881,"user_tz":-480,"elapsed":19839,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"7d1f5e19-348a-4c46-ea63-a74630d05573"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","%cd drive/MyDrive/detectron2\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZV6ogBhse1p","executionInfo":{"status":"ok","timestamp":1694077820565,"user_tz":-480,"elapsed":560,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"586ade38-04ca-4a6f-f31f-e0cb756b5b03"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/detectron2\n"," 018_Color.png                              output2.mp4\n"," 1.jpg                                      output_cut.mp4\n"," 3.jpg                                      \u001b[0m\u001b[01;34mpanopticapi\u001b[0m/\n"," \u001b[01;34mballoon\u001b[0m/                                   \u001b[01;34mpanoptic_images\u001b[0m/\n"," balloon_dataset.zip                        path_to_output_video.mp4\n"," \u001b[01;34mbean\u001b[0m/                                      \u001b[01;34mplant\u001b[0m/\n"," \u001b[01;34mbean_masks\u001b[0m/                                plant_002.jpg\n"," \u001b[01;34mbean_set\u001b[0m/                                  plant_009.jpg\n"," \u001b[01;34mbox_disease\u001b[0m/                               plant_015.jpg\n"," \u001b[01;34mcoco_eval\u001b[0m/                                 plant1.mp4\n"," color2.png                                 plant_output.mp4\n"," \u001b[01;34mcow\u001b[0m/                                       plant_output_video.mp4\n"," \u001b[01;34mdetectron2_dc\u001b[0m/                             pre.jpg\n"," \u001b[01;34mfield\u001b[0m/                                     \u001b[01;34mroad\u001b[0m/\n"," field.mp4                                  \u001b[01;34mRoadDataset\u001b[0m/\n"," image_visual_final.mp4                     \u001b[01;34mroad_output\u001b[0m/\n"," img_18.png                                 stop.jpg\n"," img_7.png                                  \u001b[01;34mtemp\u001b[0m/\n"," \u001b[01;34mlane\u001b[0m/                                      Test_1010.jpg\n"," leaf_000001.jpg                            Test_1357.jpg\n"," leaf_color_000000.png                      test2.mp4\n"," leaf_color_000001.png                      Test_41.jpg\n"," \u001b[01;34m__MACOSX\u001b[0m/                                  Test_858.jpg\n"," \u001b[01;34mmaskrcnn-benchmark\u001b[0m/                        test.jpg\n"," model_final_edd263_pointrend_r50_3lr.pkl   test.mp4\n","'model_final_f10217 .pkl'                   \u001b[01;34mvisiual\u001b[0m/\n"," \u001b[01;34moutput\u001b[0m/\n"]}]},{"cell_type":"code","source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n","!pip install opencv-python opencv-python-headless"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBbc3WrWsmaA","executionInfo":{"status":"ok","timestamp":1694078066635,"user_tz":-480,"elapsed":240996,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"25e4742e-fcf3-433c-b576-e8f269843537"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/detectron2.git\n","  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-0keb8kgp\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-0keb8kgp\n","  Resolved https://github.com/facebookresearch/detectron2.git to commit fc9c33b1f6e5d4c37bbb46dde19af41afc1ddb2a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n","Collecting yacs>=0.1.8 (from detectron2==0.6)\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.12.3)\n","Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting black (from detectron2==0.6)\n","  Downloading black-23.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n","Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n","  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (3.10.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.57.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.4.4)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.3.7)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.41.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n","Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n","  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6112363 sha256=05f704fd9c9b34b480a8a0f8e824438e88285c23bf9339f9bc05fe19cb23bfc6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-43vgin54/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=a6c7a469b96c89c77186839aed2fc192293d0d87717d9e418aaa0177894c4acc\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=7b62cd264b4a5f290ca788dda930c76c7e140991b5977c6a36f4a02680bf1554\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built detectron2 fvcore antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n","Successfully installed antlr4-python3-runtime-4.9.3 black-23.7.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.11.2 portalocker-2.7.0 yacs-0.1.8\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"]}]},{"cell_type":"markdown","source":["# 训练过程"],"metadata":{"id":"CRU3UEv9sz54"}},{"cell_type":"markdown","source":["## 配置训练器"],"metadata":{"id":"i0T1MPc47UKk"}},{"cell_type":"code","source":["# 下面的代码块开始训练\n","# 导入依赖的包\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import cv2\n","import os\n","import random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from detectron2.data.catalog import DatasetCatalog\n","from detectron2.evaluation import COCOEvaluator"],"metadata":{"id":"xlOuSuTeszaA","executionInfo":{"status":"ok","timestamp":1694078108286,"user_tz":-480,"elapsed":1701,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## 注册训练集和验证集"],"metadata":{"id":"IEaJ30OD7W8G"}},{"cell_type":"code","source":["from detectron2.data.datasets import register_coco_panoptic_separated\n","# 全景分割\n","register_coco_panoptic_separated(\"field_train\", {}, \"./field/train/\", \"./field/train/field_train_coco_panoptic\", \"./field/train/field_train_coco_panoptic.json\", \"./field/train/field_train_coco_instance\", \"./field/train/field_train_coco_instance.json\")\n","register_coco_panoptic_separated(\"field_valid\", {}, \"./field/valid/\", \"./field/valid/field_valid_coco_panoptic\", \"./field/valid/field_valid_coco_panoptic.json\", \"./field/valid/field_valid_coco_instance\", \"./field/valid/field_valid_coco_instance.json\")"],"metadata":{"id":"v7hDh6Sfs4du","executionInfo":{"status":"ok","timestamp":1694078112802,"user_tz":-480,"elapsed":561,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\")) #全景分割模型\n","cfg.DATASETS.TRAIN = (\"field_train_separated\", ) # 设置训练集\n","cfg.DATASETS.TEST = (\"field_valid_separated\",) # 设置验证集\n","cfg.DATALOADER.NUM_WORKERS = 2 # 工作线程数量\n","cfg.SOLVER.IMS_PER_BATCH = 4 # 每个小批次的载入图像数量\n","cfg.SOLVER.BASE_LR = 0.0001 # 初始化学习率\n","cfg.SOLVER.MAX_ITER = 400 # 迭代次数\n","cfg.SOLVER.CHECKPOINT_PERIOD = 1000 # 设置保存模型检查点的周期。在每1000次迭代后将保存一次模型\n","\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml') # 设置模型的初始权重\n","cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE = 256 # 设置每张图像的区域生成网络（RPN）的候选框数量\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 # 设置每张图像的感兴趣区域（ROI）头部的训练时的候选框数量\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # 设置类别数量\n","cfg.INPUT.MASK_FORMAT = \"bitmask\" # 设置图像的掩码格式\n","\n","cfg.TEST.EVAL_PERIOD = 100 # 设置模型评估的周期\n","cfg.OUTPUT_DIR = './output/field_panoptic_fpn_R_50_3x_400iter' # 输出路径"],"metadata":{"id":"RY9h9_75tSrC","executionInfo":{"status":"ok","timestamp":1694078116543,"user_tz":-480,"elapsed":2,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class CocoTrainer(DefaultTrainer):\n","\n","  @classmethod\n","  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","\n","    if output_folder is None:\n","        os.makedirs(\"coco_eval\", exist_ok=True)\n","        output_folder = \"coco_eval\"\n","\n","    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = CocoTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkBTyYictmgE","executionInfo":{"status":"ok","timestamp":1694078704511,"user_tz":-480,"elapsed":580166,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"7db09ddd-9b34-4234-ee0d-344f0868421f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[09/07 09:15:24 d2.engine.defaults]: Model:\n","PanopticFPN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (sem_seg_head): SemSegFPNHead(\n","    (p2): Sequential(\n","      (0): Conv2d(\n","        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","    )\n","    (p3): Sequential(\n","      (0): Conv2d(\n","        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","      (1): Upsample(scale_factor=2.0, mode='bilinear')\n","    )\n","    (p4): Sequential(\n","      (0): Conv2d(\n","        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","      (1): Upsample(scale_factor=2.0, mode='bilinear')\n","      (2): Conv2d(\n","        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","      (3): Upsample(scale_factor=2.0, mode='bilinear')\n","    )\n","    (p5): Sequential(\n","      (0): Conv2d(\n","        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","      (1): Upsample(scale_factor=2.0, mode='bilinear')\n","      (2): Conv2d(\n","        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","      (3): Upsample(scale_factor=2.0, mode='bilinear')\n","      (4): Conv2d(\n","        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","      (5): Upsample(scale_factor=2.0, mode='bilinear')\n","    )\n","    (predictor): Conv2d(128, 54, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")\n","WARNING [09/07 09:15:25 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[09/07 09:15:25 d2.data.datasets.coco]: Loaded 21 images in COCO format from ./field/train/field_train_coco_instance.json\n","[09/07 09:15:25 d2.data.datasets.coco]: Loaded 21 images with semantic segmentation from ./field/train/\n","[09/07 09:15:25 d2.data.build]: Distribution of instances among all 2 categories:\n","|   category   | #instances   |  category  | #instances   |\n","|:------------:|:-------------|:----------:|:-------------|\n","| _background_ | 0            |   field    | 21           |\n","|              |              |            |              |\n","|    total     | 21           |            |              |\n","[09/07 09:15:25 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","[09/07 09:15:25 d2.data.build]: Using training sampler TrainingSampler\n","[09/07 09:15:25 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[09/07 09:15:25 d2.data.common]: Serializing 21 elements to byte tensors and concatenating them all ...\n","[09/07 09:15:25 d2.data.common]: Serialized dataset takes 0.02 MiB\n","WARNING [09/07 09:15:25 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","[09/07 09:15:25 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-PanopticSegmentation/panoptic_fpn_R_50_3x/139514569/model_final_c10459.pkl ...\n"]},{"output_type":"stream","name":"stderr","text":["model_final_c10459.pkl: 184MB [00:00, 202MB/s]                           \n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n","roi_heads.mask_head.predictor.{bias, weight}\n"]},{"output_type":"stream","name":"stdout","text":["[09/07 09:15:26 d2.engine.train_loop]: Starting training from iteration 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["[09/07 09:15:57 d2.utils.events]:  eta: 0:07:45  iter: 19  total_loss: 3.591  loss_sem_seg: 2.61  loss_rpn_cls: 0.1625  loss_rpn_loc: 0.03097  loss_cls: 0.7912  loss_box_reg: 0  loss_mask: 0    time: 1.2664  last_time: 1.2286  data_time: 0.1255  last_data_time: 0.0248   lr: 4.8453e-06  max_mem: 6393M\n","[09/07 09:16:28 d2.utils.events]:  eta: 0:07:33  iter: 39  total_loss: 3.001  loss_sem_seg: 2.189  loss_rpn_cls: 0.1467  loss_rpn_loc: 0.02828  loss_cls: 0.6647  loss_box_reg: 0  loss_mask: 0    time: 1.2838  last_time: 1.3770  data_time: 0.0461  last_data_time: 0.0614   lr: 9.8403e-06  max_mem: 6393M\n","[09/07 09:16:54 d2.utils.events]:  eta: 0:07:14  iter: 59  total_loss: 2.198  loss_sem_seg: 1.629  loss_rpn_cls: 0.117  loss_rpn_loc: 0.03132  loss_cls: 0.4617  loss_box_reg: 0  loss_mask: 0    time: 1.2902  last_time: 1.3427  data_time: 0.0445  last_data_time: 0.0259   lr: 1.4835e-05  max_mem: 6393M\n","[09/07 09:17:21 d2.utils.events]:  eta: 0:06:55  iter: 79  total_loss: 1.627  loss_sem_seg: 1.194  loss_rpn_cls: 0.09132  loss_rpn_loc: 0.02723  loss_cls: 0.2857  loss_box_reg: 0  loss_mask: 0    time: 1.3007  last_time: 1.3094  data_time: 0.0398  last_data_time: 0.0368   lr: 1.983e-05  max_mem: 6393M\n","WARNING [09/07 09:17:48 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[09/07 09:17:48 d2.data.datasets.coco]: Loaded 21 images in COCO format from ./field/valid/field_valid_coco_instance.json\n","[09/07 09:17:48 d2.data.datasets.coco]: Loaded 21 images with semantic segmentation from ./field/valid/\n","[09/07 09:17:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[09/07 09:17:48 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[09/07 09:17:48 d2.data.common]: Serializing 21 elements to byte tensors and concatenating them all ...\n","[09/07 09:17:48 d2.data.common]: Serialized dataset takes 0.02 MiB\n","WARNING [09/07 09:17:48 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[09/07 09:17:48 d2.evaluation.evaluator]: Start inference on 21 batches\n","[09/07 09:17:54 d2.evaluation.evaluator]: Inference done 11/21. Dataloading: 0.0046 s/iter. Inference: 0.1796 s/iter. Eval: 0.3258 s/iter. Total: 0.5100 s/iter. ETA=0:00:05\n","[09/07 09:17:59 d2.evaluation.evaluator]: Total inference time: 0:00:07.935942 (0.495996 s / iter per device, on 1 devices)\n","[09/07 09:17:59 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.177901 s / iter per device, on 1 devices)\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:17:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:17:59 d2.evaluation.coco_evaluation]: Per-category segm AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","[09/07 09:17:59 d2.engine.defaults]: Evaluation results for field_valid_separated in csv format:\n","[09/07 09:17:59 d2.evaluation.testing]: copypaste: Task: bbox\n","[09/07 09:17:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:17:59 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:17:59 d2.evaluation.testing]: copypaste: Task: segm\n","[09/07 09:17:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:17:59 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:17:59 d2.utils.events]:  eta: 0:06:31  iter: 99  total_loss: 1.034  loss_sem_seg: 0.7398  loss_rpn_cls: 0.07436  loss_rpn_loc: 0.02898  loss_cls: 0.173  loss_box_reg: 0  loss_mask: 0    time: 1.3044  last_time: 1.3089  data_time: 0.0454  last_data_time: 0.0441   lr: 2.4825e-05  max_mem: 6393M\n","[09/07 09:18:26 d2.utils.events]:  eta: 0:06:08  iter: 119  total_loss: 0.6095  loss_sem_seg: 0.421  loss_rpn_cls: 0.06343  loss_rpn_loc: 0.02708  loss_cls: 0.1048  loss_box_reg: 0  loss_mask: 0    time: 1.3113  last_time: 1.3372  data_time: 0.0430  last_data_time: 0.0274   lr: 2.982e-05  max_mem: 6393M\n","[09/07 09:18:53 d2.utils.events]:  eta: 0:05:42  iter: 139  total_loss: 0.3959  loss_sem_seg: 0.2581  loss_rpn_cls: 0.04857  loss_rpn_loc: 0.0235  loss_cls: 0.07129  loss_box_reg: 0  loss_mask: 0    time: 1.3136  last_time: 1.3538  data_time: 0.0404  last_data_time: 0.0390   lr: 3.4815e-05  max_mem: 6393M\n","[09/07 09:19:20 d2.utils.events]:  eta: 0:05:15  iter: 159  total_loss: 0.2632  loss_sem_seg: 0.1603  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.02456  loss_cls: 0.04643  loss_box_reg: 0  loss_mask: 0    time: 1.3156  last_time: 1.6950  data_time: 0.0498  last_data_time: 0.1432   lr: 3.981e-05  max_mem: 6393M\n","[09/07 09:19:48 d2.utils.events]:  eta: 0:04:50  iter: 179  total_loss: 0.205  loss_sem_seg: 0.125  loss_rpn_cls: 0.02592  loss_rpn_loc: 0.02088  loss_cls: 0.03204  loss_box_reg: 0  loss_mask: 0    time: 1.3281  last_time: 1.3412  data_time: 0.0660  last_data_time: 0.0412   lr: 4.4805e-05  max_mem: 6393M\n","WARNING [09/07 09:20:15 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[09/07 09:20:15 d2.data.datasets.coco]: Loaded 21 images in COCO format from ./field/valid/field_valid_coco_instance.json\n","[09/07 09:20:15 d2.data.datasets.coco]: Loaded 21 images with semantic segmentation from ./field/valid/\n","[09/07 09:20:15 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[09/07 09:20:15 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[09/07 09:20:15 d2.data.common]: Serializing 21 elements to byte tensors and concatenating them all ...\n","[09/07 09:20:15 d2.data.common]: Serialized dataset takes 0.02 MiB\n","WARNING [09/07 09:20:15 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[09/07 09:20:15 d2.evaluation.evaluator]: Start inference on 21 batches\n","[09/07 09:20:17 d2.evaluation.evaluator]: Inference done 11/21. Dataloading: 0.0090 s/iter. Inference: 0.1595 s/iter. Eval: 0.0289 s/iter. Total: 0.1974 s/iter. ETA=0:00:01\n","[09/07 09:20:19 d2.evaluation.evaluator]: Total inference time: 0:00:03.720867 (0.232554 s / iter per device, on 1 devices)\n","[09/07 09:20:19 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.160556 s / iter per device, on 1 devices)\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:20:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:20:20 d2.evaluation.coco_evaluation]: Per-category segm AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","[09/07 09:20:20 d2.engine.defaults]: Evaluation results for field_valid_separated in csv format:\n","[09/07 09:20:20 d2.evaluation.testing]: copypaste: Task: bbox\n","[09/07 09:20:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:20:20 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:20:20 d2.evaluation.testing]: copypaste: Task: segm\n","[09/07 09:20:20 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:20:20 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:20:20 d2.utils.events]:  eta: 0:04:24  iter: 199  total_loss: 0.1641  loss_sem_seg: 0.1003  loss_rpn_cls: 0.0168  loss_rpn_loc: 0.02115  loss_cls: 0.02495  loss_box_reg: 0  loss_mask: 0    time: 1.3281  last_time: 1.4160  data_time: 0.0411  last_data_time: 0.0570   lr: 4.98e-05  max_mem: 6393M\n","[09/07 09:20:47 d2.utils.events]:  eta: 0:03:57  iter: 219  total_loss: 0.146  loss_sem_seg: 0.08822  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.01753  loss_cls: 0.01882  loss_box_reg: 0  loss_mask: 0    time: 1.3336  last_time: 1.3715  data_time: 0.0622  last_data_time: 0.0415   lr: 5.4795e-05  max_mem: 6393M\n","[09/07 09:21:15 d2.utils.events]:  eta: 0:03:32  iter: 239  total_loss: 0.1281  loss_sem_seg: 0.07752  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.01795  loss_cls: 0.01482  loss_box_reg: 0  loss_mask: 0    time: 1.3384  last_time: 1.4820  data_time: 0.0554  last_data_time: 0.0440   lr: 5.979e-05  max_mem: 6393M\n","[09/07 09:21:42 d2.utils.events]:  eta: 0:03:05  iter: 259  total_loss: 0.1131  loss_sem_seg: 0.06719  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.01566  loss_cls: 0.01215  loss_box_reg: 0  loss_mask: 0    time: 1.3396  last_time: 1.3163  data_time: 0.0548  last_data_time: 0.0440   lr: 6.4785e-05  max_mem: 6394M\n","[09/07 09:22:09 d2.utils.events]:  eta: 0:02:39  iter: 279  total_loss: 0.09904  loss_sem_seg: 0.06109  loss_rpn_cls: 0.009603  loss_rpn_loc: 0.01666  loss_cls: 0.009964  loss_box_reg: 0  loss_mask: 0    time: 1.3390  last_time: 1.3397  data_time: 0.0420  last_data_time: 0.0478   lr: 6.978e-05  max_mem: 6394M\n","WARNING [09/07 09:22:36 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[09/07 09:22:36 d2.data.datasets.coco]: Loaded 21 images in COCO format from ./field/valid/field_valid_coco_instance.json\n","[09/07 09:22:36 d2.data.datasets.coco]: Loaded 21 images with semantic segmentation from ./field/valid/\n","[09/07 09:22:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[09/07 09:22:36 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[09/07 09:22:36 d2.data.common]: Serializing 21 elements to byte tensors and concatenating them all ...\n","[09/07 09:22:36 d2.data.common]: Serialized dataset takes 0.02 MiB\n","WARNING [09/07 09:22:36 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[09/07 09:22:36 d2.evaluation.evaluator]: Start inference on 21 batches\n","[09/07 09:22:38 d2.evaluation.evaluator]: Inference done 11/21. Dataloading: 0.0027 s/iter. Inference: 0.1374 s/iter. Eval: 0.0022 s/iter. Total: 0.1423 s/iter. ETA=0:00:01\n","[09/07 09:22:39 d2.evaluation.evaluator]: Total inference time: 0:00:02.310458 (0.144404 s / iter per device, on 1 devices)\n","[09/07 09:22:39 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.136256 s / iter per device, on 1 devices)\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.01 seconds.\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:22:39 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:22:39 d2.evaluation.coco_evaluation]: Per-category segm AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","[09/07 09:22:39 d2.engine.defaults]: Evaluation results for field_valid_separated in csv format:\n","[09/07 09:22:39 d2.evaluation.testing]: copypaste: Task: bbox\n","[09/07 09:22:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:22:39 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:22:39 d2.evaluation.testing]: copypaste: Task: segm\n","[09/07 09:22:39 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:22:39 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:22:39 d2.utils.events]:  eta: 0:02:12  iter: 299  total_loss: 0.09314  loss_sem_seg: 0.05613  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.01633  loss_cls: 0.008218  loss_box_reg: 0  loss_mask: 0    time: 1.3394  last_time: 1.3300  data_time: 0.0496  last_data_time: 0.0365   lr: 7.4775e-05  max_mem: 6394M\n","[09/07 09:23:06 d2.utils.events]:  eta: 0:01:46  iter: 319  total_loss: 0.08625  loss_sem_seg: 0.05191  loss_rpn_cls: 0.009536  loss_rpn_loc: 0.0181  loss_cls: 0.007034  loss_box_reg: 0  loss_mask: 0    time: 1.3400  last_time: 1.3101  data_time: 0.0466  last_data_time: 0.0228   lr: 7.977e-05  max_mem: 6394M\n","[09/07 09:23:33 d2.utils.events]:  eta: 0:01:19  iter: 339  total_loss: 0.07897  loss_sem_seg: 0.0485  loss_rpn_cls: 0.006526  loss_rpn_loc: 0.01576  loss_cls: 0.005876  loss_box_reg: 0  loss_mask: 0    time: 1.3399  last_time: 1.3198  data_time: 0.0444  last_data_time: 0.0393   lr: 8.4765e-05  max_mem: 6394M\n","[09/07 09:24:00 d2.utils.events]:  eta: 0:00:53  iter: 359  total_loss: 0.07796  loss_sem_seg: 0.04622  loss_rpn_cls: 0.008553  loss_rpn_loc: 0.015  loss_cls: 0.004929  loss_box_reg: 0  loss_mask: 0    time: 1.3394  last_time: 1.3350  data_time: 0.0449  last_data_time: 0.0507   lr: 8.976e-05  max_mem: 6394M\n","[09/07 09:24:27 d2.utils.events]:  eta: 0:00:26  iter: 379  total_loss: 0.07342  loss_sem_seg: 0.04433  loss_rpn_cls: 0.008043  loss_rpn_loc: 0.01454  loss_cls: 0.004518  loss_box_reg: 0  loss_mask: 0    time: 1.3396  last_time: 1.3677  data_time: 0.0478  last_data_time: 0.0615   lr: 9.4755e-05  max_mem: 6394M\n","[09/07 09:25:00 d2.utils.events]:  eta: 0:00:00  iter: 399  total_loss: 0.0704  loss_sem_seg: 0.04164  loss_rpn_cls: 0.004784  loss_rpn_loc: 0.01752  loss_cls: 0.003828  loss_box_reg: 0  loss_mask: 0    time: 1.3391  last_time: 1.3175  data_time: 0.0440  last_data_time: 0.0228   lr: 9.975e-05  max_mem: 6394M\n","[09/07 09:25:00 d2.engine.hooks]: Overall training speed: 398 iterations in 0:08:52 (1.3391 s / it)\n","[09/07 09:25:00 d2.engine.hooks]: Total training time: 0:09:25 (0:00:32 on hooks)\n","WARNING [09/07 09:25:00 d2.data.datasets.coco]: \n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","[09/07 09:25:00 d2.data.datasets.coco]: Loaded 21 images in COCO format from ./field/valid/field_valid_coco_instance.json\n","[09/07 09:25:00 d2.data.datasets.coco]: Loaded 21 images with semantic segmentation from ./field/valid/\n","[09/07 09:25:00 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","[09/07 09:25:00 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n","[09/07 09:25:00 d2.data.common]: Serializing 21 elements to byte tensors and concatenating them all ...\n","[09/07 09:25:00 d2.data.common]: Serialized dataset takes 0.02 MiB\n","WARNING [09/07 09:25:00 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","[09/07 09:25:00 d2.evaluation.evaluator]: Start inference on 21 batches\n","[09/07 09:25:02 d2.evaluation.evaluator]: Inference done 11/21. Dataloading: 0.0033 s/iter. Inference: 0.1336 s/iter. Eval: 0.0014 s/iter. Total: 0.1384 s/iter. ETA=0:00:01\n","[09/07 09:25:03 d2.evaluation.evaluator]: Total inference time: 0:00:02.262232 (0.141390 s / iter per device, on 1 devices)\n","[09/07 09:25:03 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:02 (0.133434 s / iter per device, on 1 devices)\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Saving results to coco_eval/coco_instances_results.json\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.00 seconds.\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.01 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","Loading and preparing results...\n","DONE (t=0.00s)\n","creating index...\n","index created!\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n","[09/07 09:25:03 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n","|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n","|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n","| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n","[09/07 09:25:03 d2.evaluation.coco_evaluation]: Per-category segm AP: \n","| category     | AP   | category   | AP    |\n","|:-------------|:-----|:-----------|:------|\n","| _background_ | nan  | field      | 0.000 |\n","[09/07 09:25:03 d2.engine.defaults]: Evaluation results for field_valid_separated in csv format:\n","[09/07 09:25:03 d2.evaluation.testing]: copypaste: Task: bbox\n","[09/07 09:25:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:25:03 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n","[09/07 09:25:03 d2.evaluation.testing]: copypaste: Task: segm\n","[09/07 09:25:03 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n","[09/07 09:25:03 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n"]}]},{"cell_type":"markdown","source":["## 预测一张图片"],"metadata":{"id":"8xDgtz6a7OvZ"}},{"cell_type":"code","source":["from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.data import MetadataCatalog\n","from detectron2.utils.visualizer import ColorMode, Visualizer\n","from detectron2 import model_zoo\n","from google.colab.patches import cv2_imshow\n","\n","import cv2\n","import numpy as np\n","\n","\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file('COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml'))\n","cfg.MODEL.WEIGHTS = \"./output/field_panoptic_fpn_R_50_3x_400iter/model_final.pth\"\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.99\n","cfg.MODEL.DEVICE = \"cpu\"\n","predictor = DefaultPredictor(cfg)\n","\n","\n","meta_data = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n","meta_data.stuff_classes[1] = 'field' # 强行设置一号为field\n","\n","image = cv2.imread(\"./field/train/3.jpg\")\n","predictions, segmentinfo = predictor(image)['panoptic_seg']\n","predictions[predictions > 1] = 0  # 清除其他类\n","viz = Visualizer(image[:,:,::-1], meta_data)\n","output = viz.draw_panoptic_seg_predictions(predictions.to('cpu'), segmentinfo)\n","cv2_imshow(output.get_image()[:,:,::-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":955,"output_embedded_package_id":"10O_emdfeTjSCsYnPSmSJcjqfMhIU4gCm"},"id":"ZJCx9TYW7OQv","executionInfo":{"status":"ok","timestamp":1694079707331,"user_tz":-480,"elapsed":14074,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"776dc406-e91e-49f6-903c-4319760518f6"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## 预测一个视频"],"metadata":{"id":"Jee27V_kBQl2"}},{"cell_type":"code","source":["from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.data import MetadataCatalog\n","from detectron2.utils.visualizer import ColorMode, Visualizer\n","from detectron2 import model_zoo\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import cv2\n","# cv2_imshow(image)\n","cfg = get_cfg()\n","device = 'cuda'\n","# Panoptic segmentation\n","cfg.merge_from_file(model_zoo.get_config_file('COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml'))\n","cfg.MODEL.WEIGHTS = \"./output/field_panoptic_fpn_R_50_3x_400iter/model_final.pth\"\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9\n","cfg.MODEL.DEVICE = device\n","\n","# 利用设置好的配置创建默认预测器\n","predictor = DefaultPredictor(cfg)\n","print('预测器创建成功！！！')\n","\n","cap = cv2.VideoCapture('./field.mp4') # 输入视频路径\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n","height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n","size = (int(width), int(height))\n","four_cc = cv2.VideoWriter_fourcc(*'mp4v')\n","writer = cv2.VideoWriter('./visiual/field4.mp4', four_cc, fps, size) # 输出视频路径\n","i = 0\n","\n","meta_data = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n","meta_data.stuff_classes[1] = 'field' # 强行设置一号为road\n","\n","while cap.isOpened():\n","    ok, image = cap.read()\n","    if not ok:\n","        break\n","    predictions, segmentinfo = predictor(image)['panoptic_seg']\n","    predictions[predictions > 1] = 0  # 清除其他类\n","    viz = Visualizer(image[:,:,::-1], metadata=meta_data)\n","    output = viz.draw_panoptic_seg_predictions(predictions.to('cpu'), segmentinfo)\n","    image_visual = output.get_image()[:,:,::-1]\n","    writer.write(image_visual)\n","    i += 1\n","    print(i, end=',')\n","    if i % 10 == 0:\n","        print()\n","cap.release()\n","writer.release()\n","print('视频加载完成')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjGg-sKWBQSt","executionInfo":{"status":"ok","timestamp":1694080003702,"user_tz":-480,"elapsed":204639,"user":{"displayName":"fb Zhang","userId":"13765135092039248549"}},"outputId":"f6475ec8-3d64-41f4-fa26-3556726be4fc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[09/07 09:43:19 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./output/field_panoptic_fpn_R_50_3x_400iter/model_final.pth ...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (4, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (4,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (1, 256, 1, 1) in the checkpoint but (80, 256, 1, 1) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (1,) in the checkpoint but (80,) in the model! You might want to double check if this is expected.\n","WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n","roi_heads.box_predictor.bbox_pred.{bias, weight}\n","roi_heads.box_predictor.cls_score.{bias, weight}\n","roi_heads.mask_head.predictor.{bias, weight}\n"]},{"output_type":"stream","name":"stdout","text":["预测器创建成功！！！\n","1,2,3,4,5,6,7,8,9,10,\n","11,12,13,14,15,16,17,18,19,20,\n","21,22,23,24,25,26,27,28,29,30,\n","31,32,33,34,35,36,37,38,39,40,\n","41,42,43,44,45,46,47,48,49,50,\n","51,52,53,54,55,56,57,58,59,60,\n","61,62,63,64,65,66,67,68,69,70,\n","71,72,73,74,75,76,77,78,79,80,\n","81,82,83,84,85,86,87,88,89,90,\n","91,92,93,94,95,96,97,98,99,100,\n","101,102,103,104,105,106,107,108,109,110,\n","111,112,113,114,115,116,117,118,119,120,\n","121,122,123,124,125,126,127,128,129,130,\n","131,132,133,134,135,136,137,138,139,140,\n","141,142,143,144,145,146,147,148,149,150,\n","151,152,153,154,155,156,157,158,159,160,\n","161,162,163,164,165,166,167,168,169,170,\n","171,172,173,174,175,176,177,178,179,180,\n","181,182,183,184,185,186,187,188,189,190,\n","191,192,193,194,195,196,197,198,199,200,\n","201,202,203,204,205,206,207,208,209,210,\n","211,212,213,214,215,216,217,218,219,220,\n","221,222,223,224,225,226,227,228,229,230,\n","231,232,233,234,235,236,237,238,239,240,\n","241,242,243,244,245,246,247,248,249,250,\n","251,252,253,254,255,256,257,258,259,260,\n","261,262,263,264,265,266,267,268,269,270,\n","271,272,273,274,275,276,277,278,279,280,\n","281,282,283,284,285,286,287,288,289,290,\n","291,292,293,294,295,296,297,298,299,300,\n","301,302,303,304,305,306,307,308,309,310,\n","311,312,313,314,315,316,317,318,319,320,\n","321,322,323,324,325,326,327,328,329,330,\n","331,332,333,334,335,336,337,338,339,340,\n","341,342,343,344,345,346,347,348,349,350,\n","351,352,353,354,355,356,357,358,359,360,\n","361,362,363,364,365,366,367,368,369,370,\n","371,372,373,374,375,376,377,378,379,380,\n","381,382,383,384,385,386,387,388,389,390,\n","391,392,393,394,395,396,397,398,399,400,\n","401,402,403,404,405,406,407,408,409,410,\n","411,412,413,414,415,416,417,418,419,420,\n","421,422,423,424,425,426,427,428,429,430,\n","431,432,433,434,435,436,437,438,439,440,\n","441,442,443,444,445,446,447,448,449,450,\n","视频加载完成\n"]}]}]}